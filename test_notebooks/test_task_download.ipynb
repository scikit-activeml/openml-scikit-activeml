{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.extend([\n",
    "#     '../../openml-python-OpenMLActiveClassificationTask/',\n",
    "#     '../../openml-scikit-activeml/'\n",
    "# ])\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:55.725548667Z",
     "start_time": "2023-05-11T16:02:55.680444864Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend([\n",
    "    'openml-python-OpenMLActiveClassificationTask/',\n",
    "    'openml-scikit-activeml/'\n",
    "])\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.235008099Z",
     "start_time": "2023-05-11T16:02:55.702005390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\config.py:184: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from openml.tasks import OpenMLActiveClassificationTask, TaskType\n",
    "from openml import tasks, runs\n",
    "from skactiveml.classifier import ParzenWindowClassifier\n",
    "from skactiveml.pool import UncertaintySampling, RandomSampling, ProbabilisticAL\n",
    "import openml\n",
    "import openml_skactiveml\n",
    "from openml_skactiveml import PoolSkactivemlModel\n",
    "openml.config.start_using_configuration_for_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.389021175Z",
     "start_time": "2023-05-11T16:02:57.224734745Z"
    }
   },
   "outputs": [
    {
     "ename": "OpenMLServerError",
     "evalue": "Unexpected server error when calling https://test.openml.org/api_splits/get/1650/Task_1650_splits.arff. Please contact the developers!\nStatus code: 412\nTask not providing datasplits.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\task.py:160\u001b[0m, in \u001b[0;36mOpenMLTask.download_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39;49m_from_arff_file(cached_split_file)\n\u001b[0;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    162\u001b[0m     \u001b[39m# Next, download and cache the associated split file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\split.py:90\u001b[0m, in \u001b[0;36mOpenMLSplit._from_arff_file\u001b[1;34m(cls, filename)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSplit arff \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist!\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[0;32m     91\u001b[0m file_data \u001b[39m=\u001b[39m arff\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(filename), return_type\u001b[39m=\u001b[39marff\u001b[39m.\u001b[39mDENSE_GEN)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Split arff C:\\Users\\tpham\\.openml\\org\\openml\\test\\tasks\\1650\\datasplits.arff does not exist!",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\task.py:143\u001b[0m, in \u001b[0;36mOpenMLTask._download_split\u001b[1;34m(self, cache_file)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mwith\u001b[39;00m io\u001b[39m.\u001b[39;49mopen(cache_file, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m    144\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\tpham\\\\.openml\\\\org\\\\openml\\\\test\\\\tasks\\\\1650\\\\datasplits.arff'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExpatError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:327\u001b[0m, in \u001b[0;36m_send_request\u001b[1;34m(request_method, url, data, files, md5_checksum)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[1;32m--> 327\u001b[0m __check_response(response\u001b[39m=\u001b[39;49mresponse, url\u001b[39m=\u001b[39;49murl, file_elements\u001b[39m=\u001b[39;49mfiles)\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m request_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m __is_checksum_equal(response\u001b[39m.\u001b[39mtext, md5_checksum):\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:377\u001b[0m, in \u001b[0;36m__check_response\u001b[1;34m(response, url, file_elements)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m--> 377\u001b[0m     \u001b[39mraise\u001b[39;00m __parse_server_exception(response, url, file_elements\u001b[39m=\u001b[39;49mfile_elements)\n\u001b[0;32m    378\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    379\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mheaders \u001b[39mor\u001b[39;00m response\u001b[39m.\u001b[39mheaders[\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    380\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:393\u001b[0m, in \u001b[0;36m__parse_server_exception\u001b[1;34m(response, url, file_elements)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m     server_exception \u001b[39m=\u001b[39m xmltodict\u001b[39m.\u001b[39;49mparse(response\u001b[39m.\u001b[39;49mtext)\n\u001b[0;32m    394\u001b[0m \u001b[39mexcept\u001b[39;00m xml\u001b[39m.\u001b[39mparsers\u001b[39m.\u001b[39mexpat\u001b[39m.\u001b[39mExpatError:\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\xmltodict.py:327\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(xml_input, encoding, expat, process_namespaces, namespace_separator, disable_entities, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     parser\u001b[39m.\u001b[39;49mParse(xml_input, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    328\u001b[0m \u001b[39mreturn\u001b[39;00m handler\u001b[39m.\u001b[39mitem\n",
      "\u001b[1;31mExpatError\u001b[0m: syntax error: line 1, column 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpenMLServerError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m task_id \u001b[39m=\u001b[39m \u001b[39m1650\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39m# task_id = 6175\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m task \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39;49mget_task(task_id, download_data\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\functions.py:364\u001b[0m, in \u001b[0;36mget_task\u001b[1;34m(task_id, download_data, download_qualities)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    360\u001b[0m     openml\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_remove_cache_dir_for_id(\n\u001b[0;32m    361\u001b[0m         TASKS_CACHE_DIR_NAME,\n\u001b[0;32m    362\u001b[0m         tid_cache_dir,\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    366\u001b[0m \u001b[39mreturn\u001b[39;00m task\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\functions.py:358\u001b[0m, in \u001b[0;36mget_task\u001b[1;34m(task_id, download_data, download_qualities)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m download_data:\n\u001b[0;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(task, OpenMLSupervisedTask):\n\u001b[1;32m--> 358\u001b[0m             task\u001b[39m.\u001b[39;49mdownload_split()\n\u001b[0;32m    359\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    360\u001b[0m     openml\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_remove_cache_dir_for_id(\n\u001b[0;32m    361\u001b[0m         TASKS_CACHE_DIR_NAME,\n\u001b[0;32m    362\u001b[0m         tid_cache_dir,\n\u001b[0;32m    363\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\task.py:163\u001b[0m, in \u001b[0;36mOpenMLTask.download_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39m_from_arff_file(cached_split_file)\n\u001b[0;32m    161\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    162\u001b[0m     \u001b[39m# Next, download and cache the associated split file\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_split(cached_split_file)\n\u001b[0;32m    164\u001b[0m     split \u001b[39m=\u001b[39m OpenMLSplit\u001b[39m.\u001b[39m_from_arff_file(cached_split_file)\n\u001b[0;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m split\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\tasks\\task.py:147\u001b[0m, in \u001b[0;36mOpenMLTask._download_split\u001b[1;34m(self, cache_file)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mIOError\u001b[39;00m):\n\u001b[0;32m    146\u001b[0m     split_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimation_procedure[\u001b[39m\"\u001b[39m\u001b[39mdata_splits_url\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 147\u001b[0m     openml\u001b[39m.\u001b[39;49m_api_calls\u001b[39m.\u001b[39;49m_download_text_file(\n\u001b[0;32m    148\u001b[0m         source\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(split_url),\n\u001b[0;32m    149\u001b[0m         output_path\u001b[39m=\u001b[39;49mcache_file,\n\u001b[0;32m    150\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:233\u001b[0m, in \u001b[0;36m_download_text_file\u001b[1;34m(source, output_path, md5_checksum, exists_ok, encoding)\u001b[0m\n\u001b[0;32m    231\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting [\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m] request for the URL \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, source)\n\u001b[0;32m    232\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 233\u001b[0m response \u001b[39m=\u001b[39m __read_url(source, request_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, md5_checksum\u001b[39m=\u001b[39;49mmd5_checksum)\n\u001b[0;32m    234\u001b[0m downloaded_file \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m output_path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:295\u001b[0m, in \u001b[0;36m__read_url\u001b[1;34m(url, request_method, data, md5_checksum)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mapikey:\n\u001b[0;32m    294\u001b[0m     data[\u001b[39m\"\u001b[39m\u001b[39mapi_key\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mapikey\n\u001b[1;32m--> 295\u001b[0m \u001b[39mreturn\u001b[39;00m _send_request(\n\u001b[0;32m    296\u001b[0m     request_method\u001b[39m=\u001b[39;49mrequest_method, url\u001b[39m=\u001b[39;49murl, data\u001b[39m=\u001b[39;49mdata, md5_checksum\u001b[39m=\u001b[39;49mmd5_checksum\n\u001b[0;32m    297\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-python-OpenMLActiveClassificationTask\\openml\\_api_calls.py:348\u001b[0m, in \u001b[0;36m_send_request\u001b[1;34m(request_method, url, data, files, md5_checksum)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, xml\u001b[39m.\u001b[39mparsers\u001b[39m.\u001b[39mexpat\u001b[39m.\u001b[39mExpatError):\n\u001b[0;32m    347\u001b[0m     \u001b[39mif\u001b[39;00m request_method \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m retry_counter \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_retries:\n\u001b[1;32m--> 348\u001b[0m         \u001b[39mraise\u001b[39;00m OpenMLServerError(\n\u001b[0;32m    349\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnexpected server error when calling \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Please contact the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdevelopers!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStatus code: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    351\u001b[0m                 url,\n\u001b[0;32m    352\u001b[0m                 response\u001b[39m.\u001b[39mstatus_code,\n\u001b[0;32m    353\u001b[0m                 response\u001b[39m.\u001b[39mtext,\n\u001b[0;32m    354\u001b[0m             )\n\u001b[0;32m    355\u001b[0m         )\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m retry_counter \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_retries:\n\u001b[0;32m    357\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mOpenMLServerError\u001b[0m: Unexpected server error when calling https://test.openml.org/api_splits/get/1650/Task_1650_splits.arff. Please contact the developers!\nStatus code: 412\nTask not providing datasplits."
     ]
    }
   ],
   "source": [
    "task_id = 1650\n",
    "# task_id = 6175\n",
    "task = tasks.get_task(task_id, download_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.467091846Z",
     "start_time": "2023-05-11T16:02:57.264206680Z"
    }
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.531107380Z",
     "start_time": "2023-05-11T16:02:57.313092207Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # Example on how an AL task can be created from an existing classification task\n",
    "\n",
    "# task_id = 1196\n",
    "# task = tasks.get_task(task_id)\n",
    "\n",
    "# my_task = openml.tasks.create_task(\n",
    "#     task_type=TaskType.SUPERVISED_CLASSIFICATION,\n",
    "#     dataset_id=128,\n",
    "#     target_name=\"class\",\n",
    "#     evaluation_measure=\"predictive_accuracy\",\n",
    "#     estimation_procedure_id=1,\n",
    "# )\n",
    "\n",
    "# task = OpenMLActiveClassificationTask(\n",
    "#         task_type_id=TaskType.ACTIVE_CLASSIFICATION,\n",
    "#         task_type=\"ACTIVE_CLASSIFICATION\",\n",
    "#         data_set_id=task.dataset_id,\n",
    "#         target_name=task.target_name,\n",
    "#         class_labels=task.class_labels,\n",
    "#         evaluation_measure=\"predictive_accuracy\",\n",
    "#         estimation_procedure_id=33, # 10-fold cross validation\n",
    "#         # annotation_costs=np.arange(150, dtype=float)*0+1, # hard-coded annotation cost for now\n",
    "#         batch_size=1,\n",
    "#     )\n",
    "\n",
    "# task.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "\n",
    "# model = {\n",
    "#     'query_strategy':UncertaintySampling(missing_label=None),\n",
    "#     'prediction_model':ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     'query_params':{\n",
    "#         \"clf\": ParzenWindowClassifier(missing_label=None, classes=task.class_labels)\n",
    "#     },\n",
    "#     'budget': 100000,\n",
    "# }\n",
    "\n",
    "# # TODO: Dictionary with Baseestimators do not work\n",
    "# model = PoolSkactivemlModel(\n",
    "#     query_strategy=ProbabilisticAL(missing_label=None),\n",
    "#     prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     query_params={\n",
    "#         \"clf\": ParzenWindowClassifier(missing_label=None, classes=task.class_labels)\n",
    "#     },\n",
    "#     # query_params = {},\n",
    "#     budget=100000,\n",
    "# )\n",
    "\n",
    "# model = PoolSkactivemlModel(\n",
    "#     query_strategy=RandomSampling(missing_label=None),\n",
    "#     prediction_model=SklearnClassifier(VotingClassifier(estimators=[ParzenWindowClassifier(missing_label=None, classes=task.class_labels), ParzenWindowClassifier(missing_label=None, classes=task.class_labels), ParzenWindowClassifier(missing_label=None, classes=task.class_labels)])),\n",
    "#     query_params={\n",
    "#     },\n",
    "#     # query_params = {},\n",
    "#     budget=100000,\n",
    "# )\n",
    "\n",
    "# model = PoolSkactivemlModel(\n",
    "#     query_strategy=UncertaintySampling(missing_label=None),\n",
    "#     prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     selection_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     selection_model_name='clf',\n",
    "#     extra_query_params={\n",
    "#     },\n",
    "#     budget=100000,\n",
    "# )\n",
    "\n",
    "model = PoolSkactivemlModel(\n",
    "    query_strategy=RandomSampling(missing_label=None),\n",
    "    prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "    # selection_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "    # selection_model_name='clf',\n",
    "    # extra_query_params={\n",
    "    # },\n",
    "    budget=100000,\n",
    ")\n",
    "\n",
    "# model = PoolSkactivemlModel(\n",
    "#     query_strategy=RandomSampling(missing_label=None),\n",
    "#     prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     selection_model=ParzenWindowClassifier(missing_label=None, classes=None),\n",
    "#     selection_model_name='clf',\n",
    "#     extra_query_params={\n",
    "#     },\n",
    "#     budget=100000,\n",
    "# )\n",
    "\n",
    "# TODO: Dictionary with Baseestimators do not work\n",
    "# model = PoolSkactivemlModel(\n",
    "#     query_strategy=RandomSampling(missing_label=None),\n",
    "#     prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     query_params={\n",
    "#         # \"clf\": None# ParzenWindowClassifier(missing_label=None, classes=task.class_labels)\n",
    "#     },\n",
    "#     # query_params = {},\n",
    "#     budget=100000,\n",
    "# )\n",
    "# Automatically evaluate your model on the task\n",
    "run = runs.run_model_on_task(model, task, upload_flow=False, avoid_duplicate_runs=False, n_jobs=-1, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T14:33:05.894490189Z",
     "start_time": "2023-05-11T14:33:04.396150159Z"
    }
   },
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = task.get_X_and_y()\n",
    "\n",
    "learning_curve_per_fold = []\n",
    "budgets_per_fold = []\n",
    "\n",
    "for repetition in range(1):\n",
    "    for fold in range(10):\n",
    "        fold_learning_curve = []\n",
    "        preds = run.fold_evaluations['pred_t'][0][fold]\n",
    "        budgets = run.fold_evaluations['budget_t'][0][fold]\n",
    "        y_true_idx = task.get_train_test_split_indices(repeat=repetition, fold=fold)[1]\n",
    "        y_true = np.array(task.class_labels)[y[y_true_idx]]\n",
    "        for c in range(preds.shape[0]):\n",
    "            fold_learning_curve.append(np.mean(preds[c,:] == y_true))\n",
    "        learning_curve_per_fold.append(fold_learning_curve)\n",
    "        budgets_per_fold.append(budgets)\n",
    "\n",
    "for repetition in range(1):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    fig.set_facecolor('w')\n",
    "    for fold in range(10):\n",
    "        plt.plot(budgets_per_fold[fold] , learning_curve_per_fold[fold], label=f\"{fold}_{len(learning_curve_per_fold[fold])}\")\n",
    "    # plt.plot(np.mean(learning_curve_per_fold, axis=0), label=str(fold))\n",
    "    plt.legend()\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for budgets in [budgets_per_fold[0]]:\n",
    "    plt.plot(budgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "test_export = arff.dumps(run._generate_arff_dict())\n",
    "with open('test_export.arff', 'w') as f:\n",
    "    f.write(test_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.to_filesystem('test_export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.extend([\n",
    "#     '../../openml-python-OpenMLActiveClassificationTask/',\n",
    "#     '../../openml-scikit-activeml/'\n",
    "# ])\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from openml import tasks, runs, config\n",
    "config.start_using_configuration_for_example()\n",
    "\n",
    "# Build any model you like\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Download any OpenML task (includes the datasets)\n",
    "task = tasks.get_task(119)\n",
    "\n",
    "# Automatically evaluate your model on the task\n",
    "run = runs.run_model_on_task(clf, task, upload_flow=False, avoid_duplicate_runs=False, n_jobs=1, seed=10)\n",
    "\n",
    "# Share the results on OpenML.\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.flow.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:34:32.754164934Z",
     "start_time": "2023-05-11T13:34:32.636347736Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class PoolSkactivemlModel2():\n",
    "    def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "        self.query_strategy = query_strategy\n",
    "        self.prediction_model = prediction_model\n",
    "        self.query_params = query_params\n",
    "        self.budget = budget\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        params_dict = {\n",
    "                \"query_params\": self.query_params,\n",
    "                \"budget\": self.budget,\n",
    "                \"query_strategy\":self.query_strategy,\n",
    "                \"prediction_model\":self.prediction_model\n",
    "            }\n",
    "        if deep:\n",
    "            params_dict_qs = self.query_strategy.get_params()\n",
    "            for k, v in params_dict_qs.items():\n",
    "                params_dict[f'query_strategy__{k}'] = v\n",
    "            params_dict_pm = self.prediction_model.get_params()\n",
    "            for k, v in params_dict_pm.items():\n",
    "                params_dict[f'prediction_model__{k}'] = v\n",
    "            for k, v in self.query_params.items():\n",
    "                params_dict[f'query_params+{k}'] = v\n",
    "                if hasattr(v, \"get_params\"):\n",
    "                    for k_sub, v_sub in v.get_params().items():\n",
    "                        params_dict[f'query_params+{k}__{k_sub}'] = v_sub\n",
    "        return params_dict\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            # Simple optimization to gain speed (inspect is slow)\n",
    "            return self\n",
    "        valid_params = self.get_params(deep=True)\n",
    "\n",
    "        nested_params = defaultdict(dict)  # grouped by prefix\n",
    "        for key, value in params.items():\n",
    "            key = key.replace(\"+\", \"__\")\n",
    "            key, delim, sub_key = key.partition(\"__\")\n",
    "            if key not in valid_params:\n",
    "                local_valid_params = [\"query_params\", \"budget\", \"query_strategy\", \"prediction_model\"]\n",
    "                raise ValueError(\n",
    "                    f\"Invalid parameter {key!r} for estimator {self}. \"\n",
    "                    f\"Valid parameters are: {local_valid_params!r}.\"\n",
    "                )\n",
    "            if delim:\n",
    "                nested_params[key][sub_key] = value\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "                valid_params[key] = value\n",
    "\n",
    "        for key, sub_params in nested_params.items():\n",
    "            if key == \"query_params\":\n",
    "                query_nested_params = defaultdict(dict)  # grouped by prefix\n",
    "                key, delim, sub_key = key.partition(\"__\")\n",
    "                if delim:\n",
    "                    query_nested_params[key][sub_key] = value\n",
    "                else:\n",
    "                    setattr(self, key, value)\n",
    "                    valid_params[key] = value\n",
    "            else:\n",
    "                valid_params[key].set_params(**sub_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nested_params = defaultdict(dict)  # grouped by prefix\n",
    "        for key, value in params.items():\n",
    "            key, delim, sub_key = key.partition(\"__\")\n",
    "            if key not in valid_params:\n",
    "                local_valid_params = BaseEstimator._get_param_names()\n",
    "                raise ValueError(\n",
    "                    f\"Invalid parameter {key!r} for estimator {self}. \"\n",
    "                    f\"Valid parameters are: {local_valid_params!r}.\"\n",
    "                )\n",
    "\n",
    "            if delim:\n",
    "                nested_params[key][sub_key] = value\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "                valid_params[key] = value\n",
    "\n",
    "        for key, sub_params in nested_params.items():\n",
    "            valid_params[key].set_params(**sub_params)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T14:21:51.178252042Z",
     "start_time": "2023-05-11T14:21:51.062567424Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from skactiveml.pool import UncertaintySampling\n",
    "qs = UncertaintySampling()\n",
    "clf = BaggingClassifier(ParzenWindowClassifier())\n",
    "obj = PoolSkactivemlModel(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "obj.set_params(query_params__cost_matrix=None)\n",
    "d1 = obj.get_params()\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:34:34.374790709Z",
     "start_time": "2023-05-11T13:34:34.230203344Z"
    }
   },
   "outputs": [],
   "source": [
    "obj2 = PoolSkactivemlModel2(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "d2 = obj2.get_params()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:27:30.453416465Z",
     "start_time": "2023-05-11T13:27:30.232132660Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in d1.items():\n",
    "    print(f\"{k}: {v == d2[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'a':1,'b':1}=={'a':1,'b':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = PoolSkactivemlModel(1,2,3,4)\n",
    "isinstance(obj, sklearn.base.BaseEstimator)\n",
    "# issubclass(PoolSkactivemlModel, PoolSkactivemlModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoolSkactivemlModel.__bases__\n",
    "obj.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoolSkactivemlModel.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T15:01:14.046850426Z",
     "start_time": "2023-05-11T15:01:13.968597845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class PoolSkactivemlModel():\n",
    "        def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "            self.query_strategy = query_strategy\n",
    "            self.prediction_model = prediction_model\n",
    "            self.query_params = query_params\n",
    "            self.budget = budget\n",
    "\n",
    "def _wrap_skactiveml_model(clf, model):\n",
    "    class PoolSkactivemlModel(BaseEstimator):\n",
    "        def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "            self.query_strategy = query_strategy\n",
    "            self.prediction_model = prediction_model\n",
    "            self.query_params = query_params\n",
    "            self.budget = budget\n",
    "\n",
    "    return PoolSkactivemlModel(\n",
    "        query_strategy=model.query_strategy,\n",
    "        prediction_model=model.prediction_model,\n",
    "        query_params=model.query_params,\n",
    "        budget=model.budget,\n",
    "    )\n",
    "\n",
    "obj = PoolSkactivemlModel(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "print(isinstance(obj, BaseEstimator))\n",
    "obj_new = _wrap_skactiveml_model(_, obj)\n",
    "print(isinstance(obj_new, BaseEstimator))\n",
    "print(obj_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T15:01:22.545010893Z",
     "start_time": "2023-05-11T15:01:22.497925340Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1686965f4865d96dc103f8dbe26a21474def9bc9131d2b1aa2fd03680a1d89b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('wsp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
