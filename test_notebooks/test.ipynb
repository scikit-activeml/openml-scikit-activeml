{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:55.725548667Z",
     "start_time": "2023-05-11T16:02:55.680444864Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend([\n",
    "    '../../openml-python-OpenMLActiveClassificationTask/',\n",
    "    '../../openml-scikit-activeml/'\n",
    "])\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.235008099Z",
     "start_time": "2023-05-11T16:02:55.702005390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-python-OpenMLActiveClassificationTask\\openml\\config.py:184: UserWarning: Switching to the test server https://test.openml.org/api/v1/xml to not upload results to the live server. Using the test server may result in reduced performance of the API!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from openml.tasks import OpenMLActiveClassificationTask, TaskType\n",
    "from openml import tasks, runs\n",
    "from skactiveml.classifier import ParzenWindowClassifier\n",
    "from skactiveml.pool import UncertaintySampling, RandomSampling, ProbabilisticAL\n",
    "import openml\n",
    "import openml_skactiveml\n",
    "from openml_skactiveml import PoolSkactivemlModel\n",
    "openml.config.start_using_configuration_for_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.389021175Z",
     "start_time": "2023-05-11T16:02:57.224734745Z"
    }
   },
   "outputs": [],
   "source": [
    "task_id = 5199\n",
    "# task_id = 6175\n",
    "task = tasks.get_task(task_id, download_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.467091846Z",
     "start_time": "2023-05-11T16:02:57.264206680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Active Classification Task\n",
       "=================================\n",
       "Task Type Description: https://test.openml.org/tt/TaskType.ACTIVE_CLASSIFICATION\n",
       "Task ID..............: 5199\n",
       "Task URL.............: https://test.openml.org/t/5199\n",
       "Estimation Procedure.: crossvalidation\n",
       "Evaluation Measure...: predictive_accuracy\n",
       "Target Feature.......: class\n",
       "# of Classes.........: 3\n",
       "Cost Matrix..........: Available"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T16:02:57.531107380Z",
     "start_time": "2023-05-11T16:02:57.313092207Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # Example on how an AL task can be created from an existing classification task\n",
    "\n",
    "# task_id = 1196\n",
    "# task = tasks.get_task(task_id)\n",
    "\n",
    "# my_task = openml.tasks.create_task(\n",
    "#     task_type=TaskType.SUPERVISED_CLASSIFICATION,\n",
    "#     dataset_id=128,\n",
    "#     target_name=\"class\",\n",
    "#     evaluation_measure=\"predictive_accuracy\",\n",
    "#     estimation_procedure_id=1,\n",
    "# )\n",
    "\n",
    "# task = OpenMLActiveClassificationTask(\n",
    "#         task_type_id=TaskType.ACTIVE_CLASSIFICATION,\n",
    "#         task_type=\"ACTIVE_CLASSIFICATION\",\n",
    "#         data_set_id=task.dataset_id,\n",
    "#         target_name=task.target_name,\n",
    "#         class_labels=task.class_labels,\n",
    "#         evaluation_measure=\"predictive_accuracy\",\n",
    "#         estimation_procedure_id=33, # 10-fold cross validation\n",
    "#         # annotation_costs=np.arange(150, dtype=float)*0+1, # hard-coded annotation cost for now\n",
    "#         batch_size=1,\n",
    "#     )\n",
    "\n",
    "# task.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openml==0.13.1.dev,skactiveml==0.4.0,\n",
      "numpy>=1.17.3\n",
      "scipy>=1.3.2\n",
      "joblib>=1.1.1\n",
      "threadpoolctl>=2.0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ProbabilisticAL' object has no attribute 'query_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[39m=\u001b[39m PoolSkactivemlModel(\n\u001b[0;32m     11\u001b[0m     query_strategy\u001b[39m=\u001b[39mProbabilisticAL(missing_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m),\n\u001b[0;32m     12\u001b[0m     prediction_model\u001b[39m=\u001b[39mParzenWindowClassifier(missing_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, classes\u001b[39m=\u001b[39mtask\u001b[39m.\u001b[39mclass_labels, metric_dict\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m:RandomSampling(missing_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)}),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     budget\u001b[39m=\u001b[39m\u001b[39m100000\u001b[39m,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[39m# Automatically evaluate your model on the task\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m run \u001b[39m=\u001b[39m runs\u001b[39m.\u001b[39;49mrun_model_on_task(model, task, upload_flow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, avoid_duplicate_runs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, seed\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-python-OpenMLActiveClassificationTask\\openml\\runs\\functions.py:132\u001b[0m, in \u001b[0;36mrun_model_on_task\u001b[1;34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[39mreturn\u001b[39;00m task\n\u001b[0;32m    130\u001b[0m task \u001b[39m=\u001b[39m get_task_and_type_conversion(task)\n\u001b[1;32m--> 132\u001b[0m run \u001b[39m=\u001b[39m run_flow_on_task(\n\u001b[0;32m    133\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    134\u001b[0m     flow\u001b[39m=\u001b[39;49mflow,\n\u001b[0;32m    135\u001b[0m     avoid_duplicate_runs\u001b[39m=\u001b[39;49mavoid_duplicate_runs,\n\u001b[0;32m    136\u001b[0m     flow_tags\u001b[39m=\u001b[39;49mflow_tags,\n\u001b[0;32m    137\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m    138\u001b[0m     add_local_measures\u001b[39m=\u001b[39;49madd_local_measures,\n\u001b[0;32m    139\u001b[0m     upload_flow\u001b[39m=\u001b[39;49mupload_flow,\n\u001b[0;32m    140\u001b[0m     dataset_format\u001b[39m=\u001b[39;49mdataset_format,\n\u001b[0;32m    141\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    142\u001b[0m )\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m return_flow:\n\u001b[0;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m run, flow\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-python-OpenMLActiveClassificationTask\\openml\\runs\\functions.py:274\u001b[0m, in \u001b[0;36mrun_flow_on_task\u001b[1;34m(flow, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[0;32m    268\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    269\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe model is already fitted!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m This might cause inconsistency in comparison of results.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m     )\n\u001b[0;32m    273\u001b[0m \u001b[39m# execute the run\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m res \u001b[39m=\u001b[39m _run_task_get_arffcontent(\n\u001b[0;32m    275\u001b[0m     model\u001b[39m=\u001b[39;49mflow\u001b[39m.\u001b[39;49mmodel,\n\u001b[0;32m    276\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    277\u001b[0m     extension\u001b[39m=\u001b[39;49mflow\u001b[39m.\u001b[39;49mextension,\n\u001b[0;32m    278\u001b[0m     add_local_measures\u001b[39m=\u001b[39;49madd_local_measures,\n\u001b[0;32m    279\u001b[0m     dataset_format\u001b[39m=\u001b[39;49mdataset_format,\n\u001b[0;32m    280\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    281\u001b[0m )\n\u001b[0;32m    283\u001b[0m data_content, trace, fold_evaluations, sample_evaluations \u001b[39m=\u001b[39m res\n\u001b[0;32m    284\u001b[0m fields \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39mrun_environment, time\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%c\u001b[39;00m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mCreated by run_flow_on_task\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-python-OpenMLActiveClassificationTask\\openml\\runs\\functions.py:483\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent\u001b[1;34m(model, task, extension, add_local_measures, dataset_format, n_jobs)\u001b[0m\n\u001b[0;32m    479\u001b[0m _config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_config_as_dict()\n\u001b[0;32m    480\u001b[0m \u001b[39m# Execute runs in parallel\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[39m# assuming the same number of tasks as workers (n_jobs), the total compute time for this\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m# statement will be similar to the slowest run\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m job_rvals \u001b[39m=\u001b[39m Parallel(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[0;32m    484\u001b[0m     delayed(_run_task_get_arffcontent_parallel_helper)(\n\u001b[0;32m    485\u001b[0m         extension\u001b[39m=\u001b[39;49mextension,\n\u001b[0;32m    486\u001b[0m         fold_no\u001b[39m=\u001b[39;49mfold_no,\n\u001b[0;32m    487\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    488\u001b[0m         rep_no\u001b[39m=\u001b[39;49mrep_no,\n\u001b[0;32m    489\u001b[0m         sample_no\u001b[39m=\u001b[39;49msample_no,\n\u001b[0;32m    490\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    491\u001b[0m         dataset_format\u001b[39m=\u001b[39;49mdataset_format,\n\u001b[0;32m    492\u001b[0m         configuration\u001b[39m=\u001b[39;49m_config,\n\u001b[0;32m    493\u001b[0m     )\n\u001b[0;32m    494\u001b[0m     \u001b[39mfor\u001b[39;49;00m n_fit, rep_no, fold_no, sample_no \u001b[39min\u001b[39;49;00m jobs\n\u001b[0;32m    495\u001b[0m )  \u001b[39m# job_rvals contain the output of all the runs with one-to-one correspondence with `jobs`\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mfor\u001b[39;00m n_fit, rep_no, fold_no, sample_no \u001b[39min\u001b[39;00m jobs:\n\u001b[0;32m    498\u001b[0m     pred_y, proba_y, test_indices, test_y, trace, user_defined_measures_fold \u001b[39m=\u001b[39m job_rvals[\n\u001b[0;32m    499\u001b[0m         n_fit \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    500\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\tpham\\anaconda3\\envs\\scikitactiveml-openml\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-python-OpenMLActiveClassificationTask\\openml\\runs\\functions.py:726\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent_parallel_helper\u001b[1;34m(extension, fold_no, model, rep_no, sample_no, task, dataset_format, configuration)\u001b[0m\n\u001b[0;32m    716\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(task\u001b[39m.\u001b[39mtask_type)\n\u001b[0;32m    717\u001b[0m config\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    718\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mGoing to run model \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m on dataset \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for repeat \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m fold \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sample \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    719\u001b[0m         \u001b[39mstr\u001b[39m(model),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    724\u001b[0m     )\n\u001b[0;32m    725\u001b[0m )\n\u001b[1;32m--> 726\u001b[0m pred_y, proba_y, user_defined_measures_fold, trace, \u001b[39m=\u001b[39m extension\u001b[39m.\u001b[39;49m_run_model_on_fold(\n\u001b[0;32m    727\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    728\u001b[0m     task\u001b[39m=\u001b[39;49mtask,\n\u001b[0;32m    729\u001b[0m     X_train\u001b[39m=\u001b[39;49mtrain_x,\n\u001b[0;32m    730\u001b[0m     y_train\u001b[39m=\u001b[39;49mtrain_y,\n\u001b[0;32m    731\u001b[0m     rep_no\u001b[39m=\u001b[39;49mrep_no,\n\u001b[0;32m    732\u001b[0m     fold_no\u001b[39m=\u001b[39;49mfold_no,\n\u001b[0;32m    733\u001b[0m     X_test\u001b[39m=\u001b[39;49mtest_x,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    735\u001b[0m \u001b[39mreturn\u001b[39;00m pred_y, proba_y, test_indices, test_y, trace, user_defined_measures_fold\n",
      "File \u001b[1;32mc:\\Users\\tpham\\Desktop\\Arbeit\\openml-skactiveml\\openml-scikit-activeml\\test_notebooks\\../../openml-scikit-activeml\\openml_skactiveml\\extension.py:420\u001b[0m, in \u001b[0;36mSkactivemlExtension._run_model_on_fold\u001b[1;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[0;32m    417\u001b[0m         result\u001b[39m.\u001b[39mloc[obs, prediction] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m--> 420\u001b[0m query_strategy \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mclone(model\u001b[39m.\u001b[39;49mquery_strategy)\n\u001b[0;32m    421\u001b[0m prediction_model \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mclone(model\u001b[39m.\u001b[39mprediction_model)\n\u001b[0;32m    422\u001b[0m query_params \u001b[39m=\u001b[39m deepcopy(model\u001b[39m.\u001b[39mquery_params)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ProbabilisticAL' object has no attribute 'query_strategy'"
     ]
    }
   ],
   "source": [
    "# model = {\n",
    "#     'query_strategy':UncertaintySampling(missing_label=None),\n",
    "#     'prediction_model':ParzenWindowClassifier(missing_label=None, classes=task.class_labels),\n",
    "#     'query_params':{\n",
    "#         \"clf\": ParzenWindowClassifier(missing_label=None, classes=task.class_labels)\n",
    "#     },\n",
    "#     'budget': 100000,\n",
    "# }\n",
    "\n",
    "# TODO: Dictionary with Baseestimators do not work\n",
    "model = PoolSkactivemlModel(\n",
    "    query_strategy=ProbabilisticAL(missing_label=None),\n",
    "    prediction_model=ParzenWindowClassifier(missing_label=None, classes=task.class_labels, metric_dict={'gamma':RandomSampling(missing_label=None)}),\n",
    "    query_params={\n",
    "        \"clf\": ParzenWindowClassifier(missing_label=None, classes=task.class_labels)\n",
    "    },\n",
    "    # query_params = {},\n",
    "    budget=100000,\n",
    ")\n",
    "# Automatically evaluate your model on the task\n",
    "run = runs.run_model_on_task(model, task, upload_flow=False, avoid_duplicate_runs=False, n_jobs=1, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T14:33:05.894490189Z",
     "start_time": "2023-05-11T14:33:04.396150159Z"
    }
   },
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = task.get_X_and_y()\n",
    "\n",
    "learning_curve_per_fold = []\n",
    "budgets_per_fold = []\n",
    "\n",
    "for repetition in range(1):\n",
    "    for fold in range(10):\n",
    "        fold_learning_curve = []\n",
    "        preds = run.fold_evaluations['pred_t'][0][fold]\n",
    "        budgets = run.fold_evaluations['budget_t'][0][fold]\n",
    "        y_true_idx = task.get_train_test_split_indices(repeat=repetition, fold=fold)[1]\n",
    "        y_true = np.array(task.class_labels)[y[y_true_idx]]\n",
    "        for c in range(preds.shape[0]):\n",
    "            fold_learning_curve.append(np.mean(preds[c,:] == y_true))\n",
    "        learning_curve_per_fold.append(fold_learning_curve)\n",
    "        budgets_per_fold.append(budgets)\n",
    "\n",
    "for repetition in range(1):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    fig.set_facecolor('w')\n",
    "    for fold in range(10):\n",
    "        plt.plot(budgets_per_fold[fold] , learning_curve_per_fold[fold], label=f\"{fold}_{len(learning_curve_per_fold[fold])}\")\n",
    "    # plt.plot(np.mean(learning_curve_per_fold, axis=0), label=str(fold))\n",
    "    plt.legend()\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for budgets in [budgets_per_fold[0]]:\n",
    "    plt.plot(budgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "test_export = arff.dumps(run._generate_arff_dict())\n",
    "with open('test_export.arff', 'w') as f:\n",
    "    f.write(test_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.to_filesystem('test_export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.impute\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import ensemble\n",
    "from openml import tasks, runs\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Build any model you like\n",
    "# clf = ensemble.AdaBoostClassifier(estimator=DecisionTreeClassifier())\n",
    "# clf = sklearn.pipeline.Pipeline(imputer=SimpleImputer(),classifier=DecisionTreeClassifier())\n",
    "\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "\n",
    "# Download any OpenML task (includes the datasets)\n",
    "task = tasks.get_task(119)\n",
    "\n",
    "\n",
    "\n",
    "# Automatically evaluate your model on the task\n",
    "run = runs.run_model_on_task(clf, task, upload_flow=False, avoid_duplicate_runs=False, n_jobs=1, seed=10)\n",
    "\n",
    "# Share the results on OpenML.\n",
    "# run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.flow.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:34:32.754164934Z",
     "start_time": "2023-05-11T13:34:32.636347736Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class PoolSkactivemlModel2():\n",
    "    def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "        self.query_strategy = query_strategy\n",
    "        self.prediction_model = prediction_model\n",
    "        self.query_params = query_params\n",
    "        self.budget = budget\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        params_dict = {\n",
    "                \"query_params\": self.query_params,\n",
    "                \"budget\": self.budget,\n",
    "                \"query_strategy\":self.query_strategy,\n",
    "                \"prediction_model\":self.prediction_model\n",
    "            }\n",
    "        if deep:\n",
    "            params_dict_qs = self.query_strategy.get_params()\n",
    "            for k, v in params_dict_qs.items():\n",
    "                params_dict[f'query_strategy__{k}'] = v\n",
    "            params_dict_pm = self.prediction_model.get_params()\n",
    "            for k, v in params_dict_pm.items():\n",
    "                params_dict[f'prediction_model__{k}'] = v\n",
    "            for k, v in self.query_params.items():\n",
    "                params_dict[f'query_params+{k}'] = v\n",
    "                if hasattr(v, \"get_params\"):\n",
    "                    for k_sub, v_sub in v.get_params().items():\n",
    "                        params_dict[f'query_params+{k}__{k_sub}'] = v_sub\n",
    "        return params_dict\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if not params:\n",
    "            # Simple optimization to gain speed (inspect is slow)\n",
    "            return self\n",
    "        valid_params = self.get_params(deep=True)\n",
    "\n",
    "        nested_params = defaultdict(dict)  # grouped by prefix\n",
    "        for key, value in params.items():\n",
    "            key = key.replace(\"+\", \"__\")\n",
    "            key, delim, sub_key = key.partition(\"__\")\n",
    "            if key not in valid_params:\n",
    "                local_valid_params = [\"query_params\", \"budget\", \"query_strategy\", \"prediction_model\"]\n",
    "                raise ValueError(\n",
    "                    f\"Invalid parameter {key!r} for estimator {self}. \"\n",
    "                    f\"Valid parameters are: {local_valid_params!r}.\"\n",
    "                )\n",
    "            if delim:\n",
    "                nested_params[key][sub_key] = value\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "                valid_params[key] = value\n",
    "\n",
    "        for key, sub_params in nested_params.items():\n",
    "            if key == \"query_params\":\n",
    "                query_nested_params = defaultdict(dict)  # grouped by prefix\n",
    "                key, delim, sub_key = key.partition(\"__\")\n",
    "                if delim:\n",
    "                    query_nested_params[key][sub_key] = value\n",
    "                else:\n",
    "                    setattr(self, key, value)\n",
    "                    valid_params[key] = value\n",
    "            else:\n",
    "                valid_params[key].set_params(**sub_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nested_params = defaultdict(dict)  # grouped by prefix\n",
    "        for key, value in params.items():\n",
    "            key, delim, sub_key = key.partition(\"__\")\n",
    "            if key not in valid_params:\n",
    "                local_valid_params = BaseEstimator._get_param_names()\n",
    "                raise ValueError(\n",
    "                    f\"Invalid parameter {key!r} for estimator {self}. \"\n",
    "                    f\"Valid parameters are: {local_valid_params!r}.\"\n",
    "                )\n",
    "\n",
    "            if delim:\n",
    "                nested_params[key][sub_key] = value\n",
    "            else:\n",
    "                setattr(self, key, value)\n",
    "                valid_params[key] = value\n",
    "\n",
    "        for key, sub_params in nested_params.items():\n",
    "            valid_params[key].set_params(**sub_params)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T14:21:51.178252042Z",
     "start_time": "2023-05-11T14:21:51.062567424Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from skactiveml.pool import UncertaintySampling\n",
    "qs = UncertaintySampling()\n",
    "clf = BaggingClassifier(ParzenWindowClassifier())\n",
    "obj = PoolSkactivemlModel(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "obj.set_params(query_params__cost_matrix=None)\n",
    "d1 = obj.get_params()\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:34:34.374790709Z",
     "start_time": "2023-05-11T13:34:34.230203344Z"
    }
   },
   "outputs": [],
   "source": [
    "obj2 = PoolSkactivemlModel2(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "d2 = obj2.get_params()\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T13:27:30.453416465Z",
     "start_time": "2023-05-11T13:27:30.232132660Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in d1.items():\n",
    "    print(f\"{k}: {v == d2[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'a':1,'b':1}=={'a':1,'b':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = PoolSkactivemlModel(1,2,3,4)\n",
    "isinstance(obj, sklearn.base.BaseEstimator)\n",
    "# issubclass(PoolSkactivemlModel, PoolSkactivemlModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoolSkactivemlModel.__bases__\n",
    "obj.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoolSkactivemlModel.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T15:01:14.046850426Z",
     "start_time": "2023-05-11T15:01:13.968597845Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class PoolSkactivemlModel():\n",
    "        def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "            self.query_strategy = query_strategy\n",
    "            self.prediction_model = prediction_model\n",
    "            self.query_params = query_params\n",
    "            self.budget = budget\n",
    "\n",
    "def _wrap_skactiveml_model(clf, model):\n",
    "    class PoolSkactivemlModel(BaseEstimator):\n",
    "        def __init__(self, query_strategy, prediction_model, query_params, budget):\n",
    "            self.query_strategy = query_strategy\n",
    "            self.prediction_model = prediction_model\n",
    "            self.query_params = query_params\n",
    "            self.budget = budget\n",
    "\n",
    "    return PoolSkactivemlModel(\n",
    "        query_strategy=model.query_strategy,\n",
    "        prediction_model=model.prediction_model,\n",
    "        query_params=model.query_params,\n",
    "        budget=model.budget,\n",
    "    )\n",
    "\n",
    "obj = PoolSkactivemlModel(query_strategy=qs, prediction_model=clf, query_params={'clf': clf}, budget=5)\n",
    "print(isinstance(obj, BaseEstimator))\n",
    "obj_new = _wrap_skactiveml_model(_, obj)\n",
    "print(isinstance(obj_new, BaseEstimator))\n",
    "print(obj_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-11T15:01:22.545010893Z",
     "start_time": "2023-05-11T15:01:22.497925340Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1686965f4865d96dc103f8dbe26a21474def9bc9131d2b1aa2fd03680a1d89b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('wsp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
